# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_9gX8qbNv8g4wF4pG_zMubvdi9WE7cRk
"""

from langchain_google_genai import ChatGoogleGenerativeAI

from langchain.prompts.prompt import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import os

if __name__ == '__main__':
  summary_prompt = """
You are a translater where you will be given input text
{input}
you need to translate that input text into desired language i.e {convertLanguage}
"""
  prompt_tempalate = PromptTemplate(input_variables=["input", "convertlanguage"], template=summary_prompt)
  llm = ChatGoogleGenerativeAI(
  model="gemini-1.5-flash",
  api_key='AIzaSyCmucqg27wsd7eD-GxTwI_MkPkywA2Tu6c'
)
chain = prompt_tempalate | llm
res = chain.invoke({"input": "My name is saraswathi and I live in Delhi.","convertLanguage":"hindi"});
print(res)

from langchain_google_genai import ChatGoogleGenerativeAI

if __name__ == '__main__':
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", api_key='AIzaSyADZK_OPQKdY-CfWpy1nT-9dSxoxFKfTBY')

    output = llm.invoke("What is the capital of India?")

    print(output)

from dotenv import load_dotenv
import os
load_dotenv

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_pinecone import PineconeVectorStore
from langchain_huggingface import HuggingFaceEmbeddings
import os
from dotenv import load_dotenv, find_dotenv
pinecone_api_key = os.getenv("pcsk_2DYBWs_7e6e3QMGXMcQ4CMkfqZL7SsP5nrHDSHZotv2eCcqefM2S6q9XNqGwxU2vXcFffu")
PINECONE_API_KEY = os.environ.get("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.environ.get("PINECONE_ENVIRONMENT")
INDEX_NAME = os.environ.get("INDEX_NAME")

import os
os.environ["PINECONE_API_KEY"] = "pcsk_2DYBWs_7e6e3QMGXMcQ4CMkfqZL7SsP5nrHDSHZotv2eCcqefM2S6q9XNqGwxU2vXcFffu"
os.environ["PINECONE_ENVIRONMENT"] = "PINECONE_ENVIRONMENT"
os.environ["INDEX_NAME"] = "indexname"
from google.colab import drive
drive.mount('/content/drive') # Mount your Google Drive

from langchain.document_loaders import TextLoader
if __name__ == "__main__":
  print("Loading Documents...")
  loader = TextLoader("/content/drive/MyDrive/Colab Notebooks/info.txt")
  document = loader. load()
  print(f"Loaded (len(document)> documents")

print("Splitting Documents...")
splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
split_documents = splitter.split_documents(document)
print(f"Split ({len(document)}) documents into ({len(split_documents)}) chunks")

from sentence_transformers import SentenceTransformer

# Load the model (this will download it if not already available)
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Example usage
sentence_embedding = model.encode("This is an example sentence.")
print(sentence_embedding.shape)  # Output: (384,)

from huggingface_hub import snapshot_download

snapshot_download(repo_id="sentence-transformers/all-MiniLM-L6-v2")

from langchain_community.vectorstores import Pinecone
from langchain_openai import OpenAIEmbeddings  # Updated import
from pinecone import Pinecone as PineconeClient
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Initialize Pinecone
pinecone_client = PineconeClient(api_key="pcsk_2DYBWs_7e6e3QMGXMcQ4CMkfqZL7SsP5nrHDSHZotv2eCcqefM2S6q9XNqGwxU2vXcFffu")  # Replace securely
index_name = "indexname"

# Prepare documents
split_documents = RecursiveCharacterTextSplitter().create_documents(["Your text here"])

# Load embeddings with API key
embeddings = OpenAIEmbeddings(openai_api_key="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")  # Fix

!pip install langchain_openai